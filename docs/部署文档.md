# AIé‰´å®å¸ˆé¡¹ç›®å¯åŠ¨æŒ‡å—

æœ¬é¡¹ç›®æä¾›äº†å¤šç§å¯åŠ¨æ–¹å¼ï¼Œé€‚åº”ä¸åŒçš„å¼€å‘å’Œéƒ¨ç½²éœ€æ±‚ã€‚

## ğŸ“‹ ç›®å½•

- [å¿«é€Ÿå¯åŠ¨](#å¿«é€Ÿå¯åŠ¨)
- [å¯åŠ¨è„šæœ¬è¯´æ˜](#å¯åŠ¨è„šæœ¬è¯´æ˜)
- [ç³»ç»Ÿè¦æ±‚](#ç³»ç»Ÿè¦æ±‚)
- [é…ç½®è¯´æ˜](#é…ç½®è¯´æ˜)
- [æ•…éšœæ’é™¤](#æ•…éšœæ’é™¤)

## ğŸš€ å¿«é€Ÿå¯åŠ¨

### Windows ç”¨æˆ·
```bash
# åŒå‡»è¿è¡Œæˆ–åœ¨å‘½ä»¤è¡Œæ‰§è¡Œ
start.bat
```

### Linux/Mac ç”¨æˆ·
```bash
# æ·»åŠ æ‰§è¡Œæƒé™å¹¶è¿è¡Œ
chmod +x start.sh
./start.sh
```

### è·¨å¹³å° Python å¯åŠ¨
```bash
# å®‰è£…ä¾èµ–ï¼ˆå¯é€‰ï¼‰
pip install colorama python-dotenv requests

# è¿è¡Œå¯åŠ¨è„šæœ¬
python start.py
```

## ğŸ“ å¯åŠ¨è„šæœ¬è¯´æ˜

### 1. æ··åˆå¯åŠ¨æ¨¡å¼ï¼ˆæ¨èå¼€å‘ç¯å¢ƒï¼‰

**æ–‡ä»¶ï¼š** `start.bat` / `start.sh` / `start.py`

**ç‰¹ç‚¹ï¼š**
- Docker è¿è¡Œä¾èµ–æœåŠ¡ï¼ˆMilvusã€Redisï¼‰
- æœ¬åœ°è¿è¡Œåº”ç”¨æœåŠ¡ï¼ˆå‰ç«¯ã€åç«¯ï¼‰
- æ”¯æŒçƒ­é‡è½½å’Œè°ƒè¯•
- å¯åŠ¨é€Ÿåº¦å¿«

**é€‚ç”¨åœºæ™¯ï¼š**
- æ—¥å¸¸å¼€å‘è°ƒè¯•
- ä»£ç ä¿®æ”¹å’Œæµ‹è¯•
- æ€§èƒ½è°ƒä¼˜

### 2. å®Œå…¨å®¹å™¨åŒ–éƒ¨ç½²

**æ–‡ä»¶ï¼š** `docker-compose.full.yml`

```bash
# å¯åŠ¨æ‰€æœ‰æœåŠ¡
docker-compose -f docker-compose.full.yml up -d

# å¯åŠ¨å¼€å‘ç¯å¢ƒï¼ˆåŒ…å«ç®¡ç†ç•Œé¢ï¼‰
docker-compose -f docker-compose.full.yml --profile development up -d

# å¯åŠ¨ç”Ÿäº§ç¯å¢ƒï¼ˆåŒ…å«Nginxï¼‰
docker-compose -f docker-compose.full.yml --profile production up -d

# å¯åŠ¨ç›‘æ§ç¯å¢ƒ
docker-compose -f docker-compose.full.yml --profile monitoring up -d
```

**é€‚ç”¨åœºæ™¯ï¼š**
- ç”Ÿäº§ç¯å¢ƒéƒ¨ç½²
- CI/CD æµæ°´çº¿
- å¤šç¯å¢ƒä¸€è‡´æ€§

### 3. ä»…ä¾èµ–æœåŠ¡

**æ–‡ä»¶ï¼š** `docker-compose.dependencies.yml`

```bash
# ä»…å¯åŠ¨ä¾èµ–æœåŠ¡
docker-compose -f docker-compose.dependencies.yml up -d

# åŒ…å«ç®¡ç†ç•Œé¢
docker-compose -f docker-compose.dependencies.yml --profile management up -d
```

**é€‚ç”¨åœºæ™¯ï¼š**
- è‡ªå®šä¹‰åº”ç”¨å¯åŠ¨æ–¹å¼
- å¾®æœåŠ¡å¼€å‘
- æœåŠ¡è§£è€¦æµ‹è¯•

## ğŸ“¦ æ¨¡å‹ä¸‹è½½

åœ¨é¦–æ¬¡ä½¿ç”¨æœ¬é¡¹ç›®å‰ï¼Œéœ€è¦ä¸‹è½½å¿…è¦çš„AIæ¨¡å‹æ–‡ä»¶ï¼š

### InternVL3.5 å¤šæ¨¡æ€æ¨¡å‹ä¸‹è½½

```bash
# å®‰è£… modelscope å·¥å…·
pip install modelscope

# ä¸‹è½½ InternVL3.5-1B æ¨¡å‹
modelscope download --model OpenGVLab/InternVL3_5-1B --local_dir .\models\InternVL3_5-1B\

# æˆ–è€…ä¸‹è½½å…¶ä»–ç‰ˆæœ¬ï¼ˆå¯é€‰ï¼‰
# modelscope download --model OpenGVLab/InternVL3_5-4B --local_dir .\models\InternVL3_5-4B\
# modelscope download --model OpenGVLab/InternVL3_5-8B --local_dir .\models\InternVL3_5-8B\
```

### å…¶ä»–æ¨¡å‹ä¸‹è½½ï¼ˆå¯é€‰ï¼‰

```bash
# CLIP æ¨¡å‹ï¼ˆå¦‚éœ€æœ¬åœ°éƒ¨ç½²ï¼‰
modelscope download --model AI-ModelScope/clip-vit-base-patch32 --local_dir .\models\clip-vit-base-patch32\

# Qwen æ–‡æœ¬æ¨¡å‹ï¼ˆå¦‚éœ€æœ¬åœ°éƒ¨ç½²ï¼‰
modelscope download --model qwen/Qwen2.5-1.5B-Instruct --local_dir .\models\Qwen2.5-1.5B-Instruct\
```

### æ¨¡å‹é…ç½®

ä¸‹è½½å®Œæˆåï¼Œéœ€è¦åœ¨ `.env` æ–‡ä»¶ä¸­é…ç½®æ¨¡å‹è·¯å¾„ï¼š

```env
# InternVL3.5 æ¨¡å‹é…ç½®
INTERNVL_MODEL_PATH=./models/InternVL3_5-1B
INTERNVL_MODEL_NAME=InternVL3_5-1B
INTERNVL_MAX_TOKENS=2048
INTERNVL_TEMPERATURE=0.7

# æœ¬åœ°æ¨¡å‹å¯ç”¨å¼€å…³
USE_LOCAL_INTERNVL=true
USE_LOCAL_CLIP=false

# æµ‹è¯•æ•°æ®é›†ç”Ÿæˆé…ç½®ï¼ˆå¯é€‰ï¼‰
ENABLE_TEST_DATASET_GENERATION=true
TEST_DATASET_OUTPUT_PATH=./test_datasets
TEST_DATASET_SAMPLE_COUNT=100
```

### æµ‹è¯•æ•°æ®é›†ç”Ÿæˆ

å¦‚æœéœ€è¦ç”Ÿæˆæµ‹è¯•æ•°æ®é›†ç”¨äºæ¨¡å‹è®­ç»ƒæˆ–è¯„ä¼°ï¼Œå¯ä»¥åœ¨ `.env` æ–‡ä»¶ä¸­å¯ç”¨ç›¸å…³é…ç½®ï¼š

```env
# å¯ç”¨æµ‹è¯•æ•°æ®é›†ç”Ÿæˆ
ENABLE_TEST_DATASET_GENERATION=true
# æŒ‡å®šè¾“å‡ºè·¯å¾„
TEST_DATASET_OUTPUT_PATH=./test_datasets
# è®¾ç½®ç”Ÿæˆæ ·æœ¬æ•°é‡
TEST_DATASET_SAMPLE_COUNT=100
```

å¯ç”¨åï¼Œç³»ç»Ÿå°†è‡ªåŠ¨ç”ŸæˆåŒ…å«æ–‡ç‰©å›¾åƒå’Œæè¿°çš„æµ‹è¯•æ•°æ®é›†ï¼Œç”¨äºæ¨¡å‹æ€§èƒ½è¯„ä¼°å’Œè°ƒä¼˜ã€‚

**æ³¨æ„ï¼š** æ¨¡å‹æ–‡ä»¶è¾ƒå¤§ï¼ˆ1Bæ¨¡å‹çº¦2GBï¼Œ4Bæ¨¡å‹çº¦8GBï¼‰ï¼Œè¯·ç¡®ä¿æœ‰è¶³å¤Ÿçš„å­˜å‚¨ç©ºé—´å’Œç½‘ç»œå¸¦å®½ã€‚

## ğŸ”§ ç³»ç»Ÿè¦æ±‚

### åŸºç¡€è¦æ±‚
- **Python:** 3.9+
- **Node.js:** 16+
- **Docker:** 20.10+
- **Docker Compose:** 2.0+

### ç¡¬ä»¶è¦æ±‚
- **å†…å­˜:** 8GB+ ï¼ˆæ¨è 16GBï¼‰
- **å­˜å‚¨:** 20GB+ å¯ç”¨ç©ºé—´
- **GPU:** NVIDIA GPUï¼ˆå¯é€‰ï¼Œç”¨äºAIæ¨¡å‹åŠ é€Ÿï¼‰

### å¯é€‰ä¾èµ–
```bash
# Python å¢å¼ºåŠŸèƒ½
pip install colorama python-dotenv requests

# Conda ç¯å¢ƒç®¡ç†
conda create -n treasure_llm python=3.9
conda activate treasure_llm
```

## âš™ï¸ é…ç½®è¯´æ˜

### ç¯å¢ƒå˜é‡é…ç½®

åˆ›å»º `.env` æ–‡ä»¶ï¼ˆå‚è€ƒ `.env.example`ï¼‰ï¼š

```env
# åŸºç¡€é…ç½®
FLASK_ENV=development
SECRET_KEY=your-secret-key

# æ•°æ®åº“é…ç½®
MILVUS_HOST=localhost
MILVUS_PORT=19530
REDIS_HOST=localhost
REDIS_PORT=6379

# AIæ¨¡å‹é…ç½®
USE_LOCAL_MODELS=true
QWEN3_MODEL_PATH=/path/to/qwen3
SMOLVLM2_MODEL_PATH=/path/to/smolvlm2

# APIé…ç½®
OPENAI_API_KEY=your-openai-key
OPENAI_BASE_URL=https://api.openai.com/v1
```

### ç«¯å£é…ç½®

| æœåŠ¡ | ç«¯å£ | è¯´æ˜ |
|------|------|------|
| å‰ç«¯ | 3000 | React å¼€å‘æœåŠ¡å™¨ |
| åç«¯ | 5000 | Flask API æœåŠ¡ |
| Milvus | 19530 | å‘é‡æ•°æ®åº“ |
| Redis | 6379 | ç¼“å­˜æœåŠ¡ |
| Minio | 9000/9001 | å¯¹è±¡å­˜å‚¨ |
| Attu | 3001 | Milvus ç®¡ç†ç•Œé¢ |
| Nginx | 80/443 | åå‘ä»£ç† |
| Grafana | 3002 | ç›‘æ§é¢æ¿ |
| Prometheus | 9090 | ç›‘æ§æ•°æ® |

## ğŸ” æœåŠ¡è®¿é—®åœ°å€

å¯åŠ¨æˆåŠŸåï¼Œå¯ä»¥é€šè¿‡ä»¥ä¸‹åœ°å€è®¿é—®å„é¡¹æœåŠ¡ï¼š

- **ä¸»åº”ç”¨:** http://localhost:3000
- **APIæ–‡æ¡£:** http://localhost:5000/health
- **Milvusç®¡ç†:** http://localhost:3001 ï¼ˆå¼€å‘æ¨¡å¼ï¼‰
- **ç›‘æ§é¢æ¿:** http://localhost:3002 ï¼ˆç›‘æ§æ¨¡å¼ï¼‰

## ğŸ› ï¸ æ•…éšœæ’é™¤

### å¸¸è§é—®é¢˜

#### 1. Docker æœåŠ¡å¯åŠ¨å¤±è´¥
```bash
# æ£€æŸ¥ Docker çŠ¶æ€
docker --version
docker-compose --version

# æ¸…ç†å¹¶é‡å¯
docker-compose down
docker system prune -f
docker-compose up -d
```

#### 2. ç«¯å£è¢«å ç”¨
```bash
# Windows æŸ¥çœ‹ç«¯å£å ç”¨
netstat -ano | findstr :3000
taskkill /f /pid <PID>

# Linux/Mac æŸ¥çœ‹ç«¯å£å ç”¨
lsof -i :3000
kill -9 <PID>
```

#### 3. å‰ç«¯ä¾èµ–å®‰è£…å¤±è´¥
```bash
cd frontend

# æ¸…ç†ç¼“å­˜
npm cache clean --force
rm -rf node_modules package-lock.json

# é‡æ–°å®‰è£…
npm install
```

#### 4. åç«¯ AI æ¨¡å‹åŠ è½½å¤±è´¥
```bash
# æ£€æŸ¥æ¨¡å‹è·¯å¾„
ls -la /path/to/models

# æ£€æŸ¥ Python ç¯å¢ƒ
python -c "import torch; print(torch.__version__)"
python -c "import transformers; print(transformers.__version__)"

# é‡æ–°å®‰è£…ä¾èµ–
pip install -r backend/requirements.txt
```

#### 5. Milvus è¿æ¥å¤±è´¥
```bash
# æ£€æŸ¥ Milvus çŠ¶æ€
docker logs milvus-standalone

# é‡å¯ Milvus
docker-compose restart milvus

# ç­‰å¾…æœåŠ¡å°±ç»ª
curl http://localhost:9091/healthz
```

### æ—¥å¿—æŸ¥çœ‹

```bash
# æŸ¥çœ‹æ‰€æœ‰æœåŠ¡æ—¥å¿—
docker-compose logs -f

# æŸ¥çœ‹ç‰¹å®šæœåŠ¡æ—¥å¿—
docker-compose logs -f milvus
docker-compose logs -f redis

# æŸ¥çœ‹åº”ç”¨æ—¥å¿—
tail -f logs/backend/app.log
tail -f logs/system/system.log
```

### æ€§èƒ½ä¼˜åŒ–

#### Docker èµ„æºé…ç½®
```yaml
# docker-compose.yml ä¸­æ·»åŠ èµ„æºé™åˆ¶
services:
  milvus:
    deploy:
      resources:
        limits:
          memory: 4G
          cpus: '2.0'
```

#### GPU æ”¯æŒ
```yaml
# å¯ç”¨ GPU æ”¯æŒ
services:
  backend:
    deploy:
      resources:
        reservations:
          devices:
            - driver: nvidia
              count: 1
              capabilities: [gpu]
```

## ğŸ“ æŠ€æœ¯æ”¯æŒ

å¦‚æœé‡åˆ°é—®é¢˜ï¼Œè¯·æŒ‰ä»¥ä¸‹æ­¥éª¤æ“ä½œï¼š

1. æŸ¥çœ‹æœ¬æ–‡æ¡£çš„æ•…éšœæ’é™¤éƒ¨åˆ†
2. æ£€æŸ¥æ—¥å¿—æ–‡ä»¶è·å–è¯¦ç»†é”™è¯¯ä¿¡æ¯
3. ç¡®è®¤ç³»ç»Ÿè¦æ±‚å’Œé…ç½®æ˜¯å¦æ­£ç¡®
4. æäº¤ Issue æ—¶è¯·é™„ä¸Šï¼š
   - æ“ä½œç³»ç»Ÿä¿¡æ¯
   - é”™è¯¯æ—¥å¿—
   - å¤ç°æ­¥éª¤

## ğŸ”„ æ›´æ–°å’Œç»´æŠ¤

### æ›´æ–°ä»£ç 
```bash
git pull origin main

# é‡æ–°æ„å»ºï¼ˆå¦‚æœ‰å¿…è¦ï¼‰
docker-compose build --no-cache

# é‡å¯æœåŠ¡
docker-compose down
docker-compose up -d
```

### æ•°æ®å¤‡ä»½
```bash
# å¤‡ä»½ Milvus æ•°æ®
docker run --rm -v milvus_data:/data -v $(pwd):/backup alpine tar czf /backup/milvus_backup.tar.gz /data

# å¤‡ä»½ Redis æ•°æ®
docker run --rm -v redis_data:/data -v $(pwd):/backup alpine tar czf /backup/redis_backup.tar.gz /data
```

---

**æ³¨æ„ï¼š** é¦–æ¬¡å¯åŠ¨å¯èƒ½éœ€è¦è¾ƒé•¿æ—¶é—´æ¥ä¸‹è½½ Docker é•œåƒå’Œå®‰è£…ä¾èµ–ï¼Œè¯·è€å¿ƒç­‰å¾…ã€‚