# 🚀 AI古董鉴定系统后端接口文档

## 📋 目录
- [系统概述](#系统概述)
- [技术架构](#技术架构)
- [核心组件](#核心组件)
- [API接口文档](#api接口文档)
- [核心代码说明](#核心代码说明)
- [部署配置](#部署配置)
- [错误处理](#错误处理)

## 🎯 系统概述

AI古董鉴定系统后端基于Flask框架构建，集成了多模态AI模型、向量数据库和智能Agent，提供专业的古董鉴定服务。

### 主要功能
- 🖼️ **多模态分析**：支持图像+文本的综合鉴定
- 🤖 **智能Agent**：基于LangChain的专业古董分析代理
- 📊 **流式输出**：实时返回分析结果
- 🔍 **向量检索**：基于CLIP和Milvus的相似古董搜索
- 📋 **结构化报告**：专业的鉴定报告生成

## 🏗️ 技术架构

```
┌─────────────────────────────────────────────────────────┐
│                    前端 (React)                         │
└─────────────────────┬───────────────────────────────────┘
                      │ HTTP/WebSocket
┌─────────────────────▼───────────────────────────────────┐
│                Flask 后端服务                           │
├─────────────────────────────────────────────────────────┤
│  • app.py (主应用)                                      │
│  • routes.py (路由定义)                                 │
│  • ai_service.py (AI服务层)                            │
│  • report_formatter.py (报告格式化)                     │
└─────────────────────┬───────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────┐
│                AI核心模块                               │
├─────────────────────────────────────────────────────────┤
│  • AICore (核心AI服务)                                  │
│  • AntiqueAgent (LangChain代理)                        │
│  • CLIPEncoder (多模态编码)                             │
│  • MilvusStorage (向量数据库)                           │
└─────────────────────┬───────────────────────────────────┘
                      │
┌─────────────────────▼───────────────────────────────────┐
│              外部服务与模型                             │
├─────────────────────────────────────────────────────────┤
│  • InternVL3.5 (多模态大模型)                          │
│  • Qwen3 (文本生成模型)                                 │
│  • Milvus (向量数据库)                                  │
│  • CLIP (图像编码器)                                    │
└─────────────────────────────────────────────────────────┘
```

## 🔧 核心组件

### 1. Flask应用主体 (`app.py`)
- **功能**：Flask应用初始化、路由定义、中间件配置
- **关键特性**：
  - CORS跨域支持
  - 文件上传处理
  - 流式响应支持
  - 错误处理和日志记录

### 2. AI服务层 (`ai_service.py`)
- **功能**：AI核心功能封装、多模态分析、向量检索
- **关键组件**：
  - AICore集成
  - CLIP模型加载
  - Milvus向量数据库
  - LangChain Agent

### 3. 报告格式化器 (`report_formatter.py`)
- **功能**：AI分析结果的结构化处理
- **输出格式**：标准化JSON报告结构

## 📡 API接口文档

### 🔍 核心鉴定接口

#### 1. 古董鉴定分析
```http
POST /api/v1/appraisal
Content-Type: multipart/form-data
```

**请求参数：**
- `image` (file): 古董图片文件
- `question` (string): 用户问题描述
- `use_local_models` (boolean, optional): 是否使用本地模型

**响应格式：**
```json
{
  "success": true,
  "data": {
    "basic_reply": "基础分析回复",
    "appraisal_report": {
      "item_name": "物品名称",
      "category": "类别",
      "dynasty": "朝代",
      "material": "材质",
      "authenticity": {
        "score": 85,
        "confidence": "较高",
        "analysis": "真伪分析详情"
      },
      "value_estimation": {
        "market_value": "市场价值",
        "collection_value": "收藏价值",
        "factors": ["价值影响因素"]
      },
      "condition": {
        "overall": "整体状况",
        "details": "状况详情"
      },
      "historical_context": "历史背景",
      "recommendations": "专业建议"
    },
    "metadata": {
      "timestamp": "2024-01-15T10:30:00Z",
      "confidence_score": 0.85,
      "model_info": {}
    }
  }
}
```

#### 2. 流式鉴定分析
```http
POST /api/v1/appraisal/stream
Content-Type: multipart/form-data
```

**请求参数：**
- `image` (file): 古董图片文件
- `question` (string): 用户问题描述
- `use_local_models` (boolean, optional): 是否使用本地模型

**响应格式：** Server-Sent Events (SSE)
```
data: [START]

data: {"content": "分析片段1"}

data: {"content": "分析片段2"}

data: [DONE]
```

### 🔍 搜索与查询接口

#### 3. 古董搜索
```http
POST /api/search
Content-Type: application/json
```

**请求体：**
```json
{
  "query": "搜索关键词",
  "type": "text" // 或 "image"
}
```

**响应格式：**
```json
{
  "success": true,
  "results": [
    {
      "id": "古董ID",
      "name": "古董名称",
      "similarity": 0.95,
      "metadata": {}
    }
  ]
}
```

#### 4. AI对话
```http
POST /api/chat
Content-Type: application/json
```

**请求体：**
```json
{
  "message": "用户消息",
  "context": "上下文信息"
}
```

### 🛠️ 系统管理接口

#### 5. 健康检查
```http
GET /health
```

**响应格式：**
```json
{
  "status": "healthy",
  "timestamp": "2024-01-15T10:30:00Z",
  "version": "1.0.0"
}
```

#### 6. 系统状态
```http
GET /api/status
```

**响应格式：**
```json
{
  "ai_core_status": "active",
  "models_loaded": {
    "clip": true,
    "internvl3_5": true,
    "qwen3": true
  },
  "database_status": "connected",
  "memory_usage": "2.1GB"
}
```

#### 7. 模型切换
```http
POST /api/model/switch
Content-Type: application/json
```

**请求体：**
```json
{
  "model_type": "internvl3_5", // 或 "qwen3"
  "enable": true
}
```

### 📁 文件管理接口

#### 8. 文件上传
```http
POST /api/upload
Content-Type: multipart/form-data
```

**请求参数：**
- `file` (file): 上传的文件

#### 9. 图片访问
```http
GET /api/images/<filename>
```

#### 10. 分析结果访问
```http
GET /api/results/<filename>
```

## 💻 核心代码说明

### 1. Flask应用初始化

```python
# app.py 核心初始化代码
app = Flask(__name__)
CORS(app)

# 配置
app.config['SECRET_KEY'] = os.getenv('SECRET_KEY', 'dev-secret-key')
app.config['UPLOAD_FOLDER'] = 'uploads'
app.config['MAX_CONTENT_LENGTH'] = 16 * 1024 * 1024  # 16MB

# AI核心初始化
def init_ai_core():
    global ai_core
    try:
        ai_core = AICore(
            openai_api_key=os.getenv('OPENAI_API_KEY', ''),
            use_local_models=True,
            max_tokens=2048,
            temperature=0.7
        )
        return True
    except Exception as e:
        logger.error(f"AI核心初始化失败: {e}")
        return False
```

### 2. 流式响应处理

```python
def handle_stream_response(input_type, question=None, image_path=None):
    """处理流式响应"""
    def generate_stream():
        try:
            # 发送开始信号
            yield f"data: [START]\n\n"
            
            # 流式分析
            for text_chunk in ai_core.analyze_antique_text_stream(question):
                if text_chunk and text_chunk.strip():
                    chunk_data = {
                        "content": text_chunk,
                        "timestamp": datetime.now().isoformat()
                    }
                    yield f"data: {json.dumps(chunk_data, ensure_ascii=False)}\n\n"
            
            # 发送结束信号
            yield f"data: [DONE]\n\n"
            
        except Exception as e:
            error_data = {"error": str(e)}
            yield f"data: {json.dumps(error_data, ensure_ascii=False)}\n\n"
    
    return Response(
        generate_stream(),
        mimetype='text/event-stream',
        headers={
            'Cache-Control': 'no-cache',
            'Connection': 'keep-alive',
            'Access-Control-Allow-Origin': '*'
        }
    )
```

### 3. AI服务集成

```python
class AIService:
    """AI服务类，集成LangChain、CLIP和Milvus"""
    
    def __init__(self):
        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        
        # 初始化AI核心
        try:
            self.ai_core = AICore()
            self.use_ai_core = True
        except Exception as e:
            self.use_ai_core = False
            self._init_legacy_components()
    
    def analyze_antique_stream(self, image_path=None, description=""):
        """流式分析古董"""
        if self.use_ai_core and self.ai_core:
            yield from self._analyze_with_ai_core_stream(image_path, description)
        else:
            # 回退到传统组件
            result = self._analyze_with_legacy(image_path)
            yield result.get('description', '分析完成')
```

### 4. 报告格式化

```python
class AppraisalReportFormatter:
    """鉴宝报告格式化器"""
    
    def format_report(self, ai_analysis, user_query="", image_path=None):
        """格式化鉴宝报告为标准JSON结构"""
        try:
            basic_info = self._extract_basic_info(ai_analysis)
            authenticity = self._extract_authenticity_analysis(ai_analysis)
            value_assessment = self._extract_value_assessment(ai_analysis)
            
            report = {
                "basic_reply": ai_analysis[:200] + "..." if len(ai_analysis) > 200 else ai_analysis,
                "appraisal_report": {
                    "item_name": basic_info.get("item_name", "未知物品"),
                    "category": basic_info.get("category", "未知"),
                    "dynasty": basic_info.get("dynasty_period", "待确定"),
                    "material": basic_info.get("material_type", "待分析"),
                    "authenticity": authenticity,
                    "value_estimation": value_assessment,
                    "condition": self._extract_condition_evaluation(ai_analysis),
                    "historical_context": self._extract_historical_context_string(ai_analysis),
                    "recommendations": self._extract_recommendations(ai_analysis)
                },
                "metadata": {
                    "timestamp": datetime.now().isoformat(),
                    "confidence_score": self._calculate_confidence_score(ai_analysis)
                }
            }
            
            return report
            
        except Exception as e:
            return self._create_error_report(str(e), ai_analysis)
```

## ⚙️ 部署配置

### 环境变量
```bash
# .env 文件配置
SECRET_KEY=your-secret-key
OPENAI_API_KEY=your-openai-key
FLASK_ENV=production
FLASK_DEBUG=False

# AI模型配置
USE_LOCAL_MODELS=true
MAX_TOKENS=2048
TEMPERATURE=0.7

# 数据库配置
MILVUS_HOST=localhost
MILVUS_PORT=19530
```

### Docker部署
```dockerfile
# Dockerfile
FROM python:3.9-slim

WORKDIR /app
COPY requirements.txt .
RUN pip install -r requirements.txt

COPY . .
EXPOSE 5000

CMD ["python", "app.py"]
```

### 启动命令
```bash
# 开发环境
python app.py

# 生产环境 (使用Gunicorn)
gunicorn --bind 0.0.0.0:5000 --workers 4 app:app

# 使用Waitress (Windows)
waitress-serve --host=0.0.0.0 --port=5000 app:app
```

## 🚨 错误处理

### 错误响应格式
```json
{
  "success": false,
  "error": {
    "code": "ERROR_CODE",
    "message": "错误描述",
    "details": "详细错误信息"
  },
  "timestamp": "2024-01-15T10:30:00Z"
}
```

### 常见错误码
- `400` - 请求参数错误
- `401` - 认证失败
- `404` - 资源不存在
- `413` - 文件过大
- `500` - 服务器内部错误
- `503` - AI服务不可用

### 错误处理示例
```python
@app.errorhandler(413)
def file_too_large(error):
    return jsonify({
        'success': False,
        'error': {
            'code': 'FILE_TOO_LARGE',
            'message': '文件大小超过限制（16MB）'
        }
    }), 413

@app.errorhandler(500)
def internal_error(error):
    logger.error(f"内部服务器错误: {error}")
    return jsonify({
        'success': False,
        'error': {
            'code': 'INTERNAL_ERROR',
            'message': '服务器内部错误，请稍后重试'
        }
    }), 500
```

## 📊 性能指标

- **响应时间**：
  - 健康检查：< 50ms
  - 图片上传：< 200ms
  - AI分析：2-8秒
  - 流式输出：实时

- **并发支持**：
  - 最大并发：100个请求
  - 推荐配置：4个Worker进程

- **资源占用**：
  - 内存：2-4GB（含AI模型）
  - CPU：多核推荐
  - 存储：模型文件约10GB

## 🔧 开发调试

### 调试接口
```http
GET /api/debug/status
```

### 日志配置
```python
# 日志级别配置
logging.basicConfig(
    level=logging.INFO,
    format='%(asctime)s - %(name)s - %(levelname)s - %(message)s',
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler('backend_app.log', encoding='utf-8')
    ]
)
```

---

## 📝 更新日志

- **v1.0.0** (2024-01-15)
  - 初始版本发布
  - 支持多模态AI分析
  - 集成LangChain Agent
  - 实现流式输出
  - 完善错误处理机制

---

*本文档持续更新中，如有问题请联系开发团队。*