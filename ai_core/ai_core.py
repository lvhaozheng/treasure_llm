"""AI æ ¸å¿ƒä¸»æ§åˆ¶å™¨
æ•´åˆ CLIP ç¼–ç å™¨ã€å‘é‡æ•°æ®åº“å’Œ LangChain ä»£ç†
"""

import os
import sys
import json
import time
import traceback
from datetime import datetime
from typing import Dict, List, Any, Optional, Union
import numpy as np
from PIL import Image
from functools import wraps

# æ·»åŠ é¡¹ç›®æ ¹ç›®å½•åˆ°ç³»ç»Ÿè·¯å¾„
sys.path.append(os.path.join(os.path.dirname(__file__), '..'))
from utils.logger_config import get_ai_logger

# å¯¼å…¥æŠ¥å‘Šæ ¼å¼åŒ–å™¨
sys.path.append(os.path.join(os.path.dirname(__file__), '..', 'backend', 'services'))
try:
    from report_formatter import format_appraisal_report
    REPORT_FORMATTER_AVAILABLE = True
    logger = get_ai_logger('ai_core')
    logger.info("æŠ¥å‘Šæ ¼å¼åŒ–å™¨å¯¼å…¥æˆåŠŸ")
except ImportError as e:
    REPORT_FORMATTER_AVAILABLE = False
    logger = get_ai_logger('ai_core')
    logger.warning(f"æŠ¥å‘Šæ ¼å¼åŒ–å™¨å¯¼å…¥å¤±è´¥: {e}")

from clip_encoder import CLIPEncoder
from vector_db import MilvusClient
from langchain_agent import AntiqueAgent
from models.client import InternVL3_5Client, Qwen3Client
from optimized_query_processor import OptimizedQueryProcessor
# é…ç½®AIæ ¸å¿ƒæ¨¡å—æ—¥å¿—
logger = get_ai_logger('ai_core')


def log_method_call(method_name: str = None):
    """æ—¥å¿—è£…é¥°å™¨ï¼Œè®°å½•æ–¹æ³•è°ƒç”¨çš„è¯¦ç»†ä¿¡æ¯"""
    def decorator(func):
        @wraps(func)
        def wrapper(self, *args, **kwargs):
            # è·å–æ–¹æ³•å
            func_name = method_name or func.__name__
            
            # è®°å½•è°ƒç”¨å¼€å§‹
            start_time = time.time()
            call_id = f"{func_name}_{int(start_time * 1000) % 100000}"
            
            # è®°å½•è¾“å…¥å‚æ•°ï¼ˆå®‰å…¨å¤„ç†ï¼Œé¿å…è®°å½•æ•æ„Ÿä¿¡æ¯ï¼‰
            safe_args = []
            for i, arg in enumerate(args):
                if isinstance(arg, (str, int, float, bool)):
                    safe_args.append(str(arg)[:100])  # é™åˆ¶é•¿åº¦
                elif isinstance(arg, (list, dict)):
                    safe_args.append(f"{type(arg).__name__}(len={len(arg)})")
                else:
                    safe_args.append(f"{type(arg).__name__}")
            
            safe_kwargs = {}
            for k, v in kwargs.items():
                if isinstance(v, (str, int, float, bool)):
                    safe_kwargs[k] = str(v)[:100]  # é™åˆ¶é•¿åº¦
                elif isinstance(v, (list, dict)):
                    safe_kwargs[k] = f"{type(v).__name__}(len={len(v)})"
                else:
                    safe_kwargs[k] = f"{type(v).__name__}"
            
            logger.info(f"ğŸš€ [{call_id}] å¼€å§‹è°ƒç”¨ {func_name}")
            logger.info(f"ğŸ“¥ [{call_id}] è¾“å…¥å‚æ•°: args={safe_args}, kwargs={safe_kwargs}")
            
            try:
                # æ‰§è¡Œæ–¹æ³•
                result = func(self, *args, **kwargs)
                
                # è®°å½•æ‰§è¡Œæ—¶é—´
                end_time = time.time()
                execution_time = end_time - start_time
                
                # è®°å½•è¿”å›ç»“æœï¼ˆå®‰å…¨å¤„ç†ï¼‰
                if isinstance(result, dict):
                    result_info = f"dict(keys={list(result.keys())[:5]})"
                elif isinstance(result, (list, tuple)):
                    result_info = f"{type(result).__name__}(len={len(result)})"
                elif hasattr(result, '__iter__') and not isinstance(result, (str, bytes)):
                    result_info = "generator/iterator"
                else:
                    result_info = f"{type(result).__name__}"
                
                logger.info(f"âœ… [{call_id}] è°ƒç”¨æˆåŠŸå®Œæˆ {func_name}")
                logger.info(f"ğŸ“¤ [{call_id}] è¿”å›ç»“æœ: {result_info}")
                logger.info(f"â±ï¸ [{call_id}] æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’")
                
                return result
                
            except Exception as e:
                # è®°å½•å¼‚å¸¸
                end_time = time.time()
                execution_time = end_time - start_time
                
                logger.error(f"âŒ [{call_id}] è°ƒç”¨å¤±è´¥ {func_name}")
                logger.error(f"ğŸ’¥ [{call_id}] å¼‚å¸¸ä¿¡æ¯: {str(e)}")
                logger.error(f"â±ï¸ [{call_id}] æ‰§è¡Œæ—¶é—´: {execution_time:.3f}ç§’")
                logger.error(f"ğŸ“ [{call_id}] å¼‚å¸¸å †æ ˆ: {traceback.format_exc()}")
                
                raise
        
        return wrapper
    return decorator


class AICore:
    """AI æ ¸å¿ƒä¸»æ§åˆ¶å™¨"""
    
    def __init__(self, 
                 openai_api_key: str = "",
                 milvus_host: str = "localhost",
                 milvus_port: str = "19530",
                 clip_model_name: str = "ViT-B/32",
                 llm_model_name: str = "gpt-3.5-turbo",
                 internvl3_5_model_path: str = "",
                 max_tokens: int = 512,
                 temperature: float = 0.7):
        """
        åˆå§‹åŒ– AI æ ¸å¿ƒ
        
        Args:
            openai_api_key: OpenAI API å¯†é’¥ï¼ˆå¯é€‰ï¼Œç”¨äºLangChainä»£ç†ï¼‰
            milvus_host: Milvus æœåŠ¡å™¨åœ°å€
            milvus_port: Milvus æœåŠ¡å™¨ç«¯å£
            clip_model_name: CLIP æ¨¡å‹åç§°
            llm_model_name: LLM æ¨¡å‹åç§°
            internvl3_5_model_path: InternVL3_5-1B æœ¬åœ°æ¨¡å‹è·¯å¾„
            max_tokens: æœ€å¤§ç”Ÿæˆtokenæ•°
            temperature: ç”Ÿæˆæ¸©åº¦
        """
        self.openai_api_key = openai_api_key
        self.milvus_host = milvus_host
        self.milvus_port = milvus_port
        self.clip_model_name = clip_model_name
        self.llm_model_name = llm_model_name
        self.internvl3_5_model_path = internvl3_5_model_path
        self.max_tokens = max_tokens
        self.temperature = temperature
        
        # åˆå§‹åŒ–ç»„ä»¶
        self.clip_encoder = None
        self.vector_db = None
        self.agent = None
        self.internvl3_5_client = None
        self.optimized_query_processor = None
        
        # åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ
        self._init_cache()
        
        try:
            self._init_components()
            logger.info("AI æ ¸å¿ƒåˆå§‹åŒ–æˆåŠŸ")
        except Exception as e:
            logger.error(f"AI æ ¸å¿ƒåˆå§‹åŒ–å¤±è´¥: {e}")
            raise
    
    def _init_components(self):
        """åˆå§‹åŒ–å„ä¸ªç»„ä»¶"""
        # åˆå§‹åŒ– CLIP ç¼–ç å™¨
        self.clip_encoder = CLIPEncoder(
            model_name=self.clip_model_name
        )
        
        # åˆå§‹åŒ–å‘é‡æ•°æ®åº“
        self.vector_db = MilvusClient(
            host=self.milvus_host,
            port=self.milvus_port,
            collection_name="antique_vectors",
            dim=512  # CLIP ç‰¹å¾ç»´åº¦
        )
        
        # åˆå§‹åŒ– InternVL3_5 å®¢æˆ·ç«¯
        self._init_internvl3_5_client()
        
        # åˆå§‹åŒ– LangChain ä»£ç†ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹ï¼‰
        self.agent = AntiqueAgent(
            openai_api_key=self.openai_api_key,
            model_name=self.llm_model_name,
            temperature=self.temperature,
            max_tokens=self.max_tokens,
            use_local_models=True,  # å¯ç”¨æœ¬åœ°æ¨¡å‹æ”¯æŒ
            clip_encoder=self.clip_encoder,  # ä¼ å…¥CLIPç¼–ç å™¨
            vector_db=self.vector_db,  # ä¼ å…¥å‘é‡æ•°æ®åº“
            internvl3_5_client=self.internvl3_5_client  # ä¼ å…¥å·²åˆ›å»ºçš„InternVL3.5å®¢æˆ·ç«¯
        )
        
        # åˆå§‹åŒ–ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨ï¼ˆä¼ å…¥å·²åˆ›å»ºçš„ç»„ä»¶ï¼Œé¿å…é‡å¤åˆå§‹åŒ–ï¼‰
        self.optimized_query_processor = OptimizedQueryProcessor(
            similarity_threshold=0.6,  # ç›¸ä¼¼åº¦é˜ˆå€¼
            top_k=5,
            clip_encoder=self.clip_encoder,  # å¤ç”¨å·²åˆ›å»ºçš„CLIPç¼–ç å™¨
            milvus_client=self.vector_db,  # å¤ç”¨å·²åˆ›å»ºçš„Milvuså®¢æˆ·ç«¯
            internvl3_5_client=self.internvl3_5_client  # å¤ç”¨å·²åˆ›å»ºçš„InternVL3.5å®¢æˆ·ç«¯
        )
        
        if not self.openai_api_key:
            logger.info("æœªæä¾›OpenAI APIå¯†é’¥ï¼Œå°†ä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼ˆQwen3 + SmolVLM2ï¼‰")
        else:
            logger.info("å·²é…ç½®OpenAI APIå¯†é’¥ï¼Œæ”¯æŒLangChainä»£ç†å’Œæœ¬åœ°æ¨¡å‹æ··åˆä½¿ç”¨")
    
    def _init_internvl3_5_client(self):
        """åˆå§‹åŒ– InternVL3_5 å®¢æˆ·ç«¯"""
        try:
            # åˆ›å»º InternVL3_5 å®¢æˆ·ç«¯
            self.internvl3_5_client = InternVL3_5Client(
                model_path=self.internvl3_5_model_path if self.internvl3_5_model_path else None,
                max_tokens=self.max_tokens,
                temperature=self.temperature
            )
            
            # è®°å½•æ¨¡å‹ä¿¡æ¯
            model_info = self.internvl3_5_client.get_model_info()
            logger.info(f"ğŸ‰ InternVL3_5 æ¨¡å‹åŠ è½½ä¿¡æ¯:")
            for key, value in model_info.items():
                logger.info(f"  {key}: {value}")
                
            logger.info("âœ… InternVL3_5 å®¢æˆ·ç«¯åˆå§‹åŒ–æˆåŠŸ")
            
        except Exception as e:
            error_msg = f"InternVL3_5 å®¢æˆ·ç«¯åˆå§‹åŒ–å¤±è´¥: {e}"
            logger.error(error_msg)
            raise RuntimeError(error_msg)
    

    
    @log_method_call("analyze_antique_image_stream")
    def analyze_antique_image_stream(self, image: Union[str, Image.Image, np.ndarray], 
                                    description: str = ""):
        """
        æµå¼åˆ†æå¤è‘£å›¾åƒï¼Œä¼˜å…ˆä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨è¿›è¡Œæ™ºèƒ½åˆ¤æ–­
        
        Args:
            image: å›¾åƒè¾“å…¥ï¼ˆæ–‡ä»¶è·¯å¾„ã€PILå›¾åƒæˆ–numpyæ•°ç»„ï¼‰
            description: å¯é€‰çš„æ–‡æœ¬æè¿°
            
        Yields:
            åˆ†æç»“æœæ–‡æœ¬ç‰‡æ®µ
        """
        try:
            # æ„å»ºåˆ†ææç¤º
            if description:
                prompt = f"è¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚åˆ†æè¿™å¼ å¤è‘£æ–‡ç‰©å›¾ç‰‡ï¼š{description}ã€‚è¯·æä¾›è¯¦ç»†çš„ä¸“ä¸šé‰´å®šåˆ†æï¼ŒåŒ…æ‹¬æ–‡ç‰©ç±»å‹ã€å¹´ä»£ã€æè´¨ã€å·¥è‰ºç‰¹ç‚¹ã€çœŸä¼ªè¯„ä¼°ã€ä¿å­˜çŠ¶å†µå’Œå†å²ä»·å€¼ã€‚è¯·ç›´æ¥æä¾›åˆ†æç»“æœï¼Œä¸è¦é‡å¤ç”¨æˆ·çš„è¦æ±‚ã€‚"
            else:
                prompt = "è¯·è¯¦ç»†åˆ†æè¿™å¼ å¤è‘£æ–‡ç‰©å›¾ç‰‡ï¼ŒåŒ…æ‹¬æ–‡ç‰©ç±»å‹ã€å¹´ä»£ã€æè´¨ã€å·¥è‰ºç‰¹ç‚¹ã€çœŸä¼ªè¯„ä¼°ã€ä¿å­˜çŠ¶å†µå’Œå†å²ä»·å€¼ã€‚"
            
            # é¦–å…ˆå°è¯•ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨çš„æµå¼æ–¹æ³•
            if hasattr(self, 'optimized_query_processor') and self.optimized_query_processor:
                logger.info("ğŸ” ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨è¿›è¡Œæµå¼æ™ºèƒ½åˆ†æ")
                try:
                    # ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨çš„æµå¼æ–¹æ³•
                    for text_chunk in self.optimized_query_processor.process_image_text_query_stream(
                        image=image,
                        text_query=prompt
                    ):
                        yield text_chunk
                    return
                except Exception as e:
                    logger.warning(f"ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨æµå¼åˆ†æå¤±è´¥ï¼Œå›é€€åˆ°å¤§æ¨¡å‹: {e}")
            
            # å›é€€åˆ°InternVL3_5è¿›è¡Œæµå¼åˆ†æ
            if self.internvl3_5_client and hasattr(self.internvl3_5_client, 'chat_about_antique_stream'):
                logger.info("ä½¿ç”¨InternVL3_5è¿›è¡Œæµå¼å¤è‘£å›¾åƒåˆ†æ")
                # ä½¿ç”¨çœŸæ­£çš„æµå¼æ–¹æ³•
                for text_chunk in self.internvl3_5_client.chat_about_antique_stream(prompt, image):
                    yield text_chunk
            elif self.internvl3_5_client and hasattr(self.internvl3_5_client, 'chat_about_antique'):
                logger.info("ä½¿ç”¨InternVL3_5è¿›è¡Œæ¨¡æ‹Ÿæµå¼å¤è‘£å›¾åƒåˆ†æ")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨chat_about_antiqueæ–¹æ³•è·å–å®Œæ•´å›å¤ï¼Œç„¶åè¿›è¡Œæµå¼è¾“å‡º
                response = self.internvl3_5_client.chat_about_antique(prompt, image)
                # æŒ‰å¥å­åˆ†å‰²è¿›è¡Œæµå¼è¾“å‡º
                sentences = response.split('ã€‚')
                for sentence in sentences:
                    if sentence.strip():
                        yield sentence.strip() + 'ã€‚'
            else:
                yield "InternVL3_5å®¢æˆ·ç«¯ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµå¼å›¾åƒåˆ†æã€‚"
                
        except Exception as e:
            logger.error(f"æµå¼å¤è‘£å›¾åƒåˆ†æå¤±è´¥: {e}")
            yield f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    @log_method_call("analyze_antique_image")
    def analyze_antique_image(self, image: Union[str, Image.Image, np.ndarray], 
                            description: str = "") -> Dict[str, Any]:
        """
        åˆ†æå¤è‘£å›¾åƒ
        
        Args:
            image: å›¾åƒè¾“å…¥
            description: æ–‡æœ¬æè¿°
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            if not self.internvl3_5_client:
                raise RuntimeError("InternVL3_5å®¢æˆ·ç«¯æœªåˆå§‹åŒ–")
            
            # 1. ä½¿ç”¨ InternVL3_5 ç”Ÿæˆé‰´å®šæŠ¥å‘Š
            internvl3_5_report = self.internvl3_5_client.generate_appraisal_report(
                image=image,
                user_query=description
            )
            
            # 2. ä½¿ç”¨æ··åˆä»£ç†è¿›è¡Œåˆ†æï¼ˆä¼˜å…ˆä½¿ç”¨æœ¬åœ°æ¨¡å‹ï¼‰
            agent_analysis = None
            if self.agent:
                try:
                    agent_result = self.agent.analyze_antique(
                        image=image,
                        text_description=description
                    )
                    agent_analysis = agent_result
                except Exception as e:
                    logger.warning(f"ä»£ç†åˆ†æå¤±è´¥ï¼Œä»…ä½¿ç”¨InternVL3_5: {e}")
            
            # 3. ä½¿ç”¨ CLIP ç¼–ç å›¾åƒç”¨äºç›¸ä¼¼æ€§æœç´¢
            image_features = self.clip_encoder.encode_image(image)
            
            # 4. æœç´¢ç›¸ä¼¼å¤è‘£
            similar_antiques = self.vector_db.search_similar_images(
                query_vector=image_features.tolist(),
                top_k=5,
                score_threshold=0.6
            )
            
            # 5. æ•´åˆç»“æœå¹¶æ ¼å¼åŒ–ä¸ºæ ‡å‡†JSONç»“æ„
            if REPORT_FORMATTER_AVAILABLE and internvl3_5_report.get("analysis_text"):
                # ä½¿ç”¨æ–°çš„æ ¼å¼åŒ–å™¨ç”Ÿæˆç»“æ„åŒ–æŠ¥å‘Š
                structured_report = format_appraisal_report(
                    ai_analysis=internvl3_5_report.get("analysis_text", ""),
                    user_query=description,
                    image_path=str(image) if isinstance(image, str) else None,
                    model_info=internvl3_5_report.get("model_info", {})
                )
                
                # æ·»åŠ é¢å¤–çš„åˆ†ææ•°æ®
                structured_report["additional_analysis"] = {
                    "agent_analysis": agent_analysis,
                    "image_features": image_features.tolist(),
                    "similar_antiques": similar_antiques,
                    "internvl3_5_raw": internvl3_5_report
                }
                
                result = structured_report
            else:
                # å›é€€åˆ°åŸå§‹æ ¼å¼
                result = {
                    "internvl3_5_analysis": internvl3_5_report,
                    "agent_analysis": agent_analysis,
                    "image_features": image_features.tolist(),
                    "similar_antiques": similar_antiques,
                    "user_query": description,
                "analysis_timestamp": self._get_timestamp(),
                "model_info": {
                    "internvl3_5_model": self.internvl3_5_client.get_model_info(),
                    "clip_model": self.clip_encoder.get_model_info(),
                    "agent_info": self.agent.get_agent_info() if self.agent else None
                }
            }
            
            logger.info("åŸºäºInternVL3_5çš„å¤è‘£å›¾åƒåˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"åŸºäºInternVL3_5çš„å¤è‘£å›¾åƒåˆ†æå¤±è´¥: {e}")
            # å›é€€åˆ°LangChainæ–¹æ³•
            return self._analyze_with_langchain(image, description)
    
    @log_method_call("analyze_antique_image_optimized")
    def analyze_antique_image_optimized(self, image: Union[str, Image.Image, np.ndarray], 
                                      description: str = "") -> Dict[str, Any]:
        """
        ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨åˆ†æå¤è‘£å›¾åƒ
        
        Args:
            image: å›¾åƒè¾“å…¥
            description: æ–‡æœ¬æè¿°
            
        Returns:
            ä¼˜åŒ–çš„åˆ†æç»“æœ
        """
        try:
            if not self.optimized_query_processor:
                logger.warning("ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨æœªåˆå§‹åŒ–ï¼Œå›é€€åˆ°æ ‡å‡†åˆ†æ")
                return self.analyze_antique_image(image, description)
            
            # ä½¿ç”¨ä¼˜åŒ–æŸ¥è¯¢å¤„ç†å™¨è¿›è¡Œåˆ†æ
            result = self.optimized_query_processor.process_image_text_query(
                image=image,
                text_query=description
            )
            
            logger.info("ä¼˜åŒ–å¤è‘£å›¾åƒåˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"ä¼˜åŒ–å¤è‘£å›¾åƒåˆ†æå¤±è´¥: {e}")
            # å›é€€åˆ°æ ‡å‡†åˆ†ææ–¹æ³•
            return self.analyze_antique_image(image, description)
    
    def _analyze_with_langchain(self, image: Union[str, Image.Image, np.ndarray], 
                               description: str = "") -> Dict[str, Any]:
        """
        ä½¿ç”¨LangChainä»£ç†åˆ†æå¤è‘£ï¼ˆå›é€€æ–¹æ³•ï¼‰
        """
        try:
            if not self.agent:
                logger.warning("æœªLangChainä»£ç†æœªåˆå§‹åŒ–ï¼Œä»…è¿”å›åŸºæœ¬ä¿¡æ¯")
                # ä»…ä½¿ç”¨CLIPè¿›è¡Œç‰¹å¾æå–
                image_features = self.clip_encoder.encode_image(image)
                similar_antiques = self.vector_db.search_similar_images(
                    query_vector=image_features.tolist(),
                    top_k=5,
                    score_threshold=0.6
                )
                
                return {
                    "image_features": image_features.tolist(),
                    "similar_antiques": similar_antiques,
                    "description": description,
                    "analysis_timestamp": self._get_timestamp(),
                    "note": "ä»…è¿›è¡Œäº†å›¾åƒç‰¹å¾æå–å’Œç›¸ä¼¼æ€§æœç´¢"
                }
            
            # 1. ä½¿ç”¨ CLIP ç¼–ç å›¾åƒ
            image_features = self.clip_encoder.encode_image(image)
            
            # 2. ä½¿ç”¨ LangChain ä»£ç†åˆ†æ
            agent_result = self.agent.analyze_antique(
                image_features=image_features,
                text_description=description
            )
            
            # 3. æœç´¢ç›¸ä¼¼å¤è‘£
            similar_antiques = self.vector_db.search_similar_images(
                query_vector=image_features.tolist(),
                top_k=5,
                score_threshold=0.6
            )
            
            # 4. æ•´åˆç»“æœ
            result = {
                "image_features": image_features.tolist(),
                "agent_analysis": agent_result,
                "similar_antiques": similar_antiques,
                "description": description,
                "analysis_timestamp": self._get_timestamp()
            }
            
            logger.info("å¤è‘£å›¾åƒåˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"å¤è‘£å›¾åƒåˆ†æå¤±è´¥: {e}")
            raise
    
    @log_method_call("search_antiques_by_text")
    def search_antiques_by_text(self, query_text: str, top_k: int = 10) -> Dict[str, Any]:
        """
        é€šè¿‡æ–‡æœ¬æœç´¢å¤è‘£
        
        Args:
            query_text: æŸ¥è¯¢æ–‡æœ¬
            top_k: è¿”å›ç»“æœæ•°é‡
            
        Returns:
            æœç´¢ç»“æœ
        """
        try:
            # 1. ä½¿ç”¨ CLIP ç¼–ç æŸ¥è¯¢æ–‡æœ¬
            text_features = self.clip_encoder.encode_text(query_text)
            
            # 2. åœ¨å‘é‡æ•°æ®åº“ä¸­æœç´¢
            similar_antiques = self.vector_db.search_similar_texts(
                query_vector=text_features.tolist(),
                top_k=top_k,
                score_threshold=0.5
            )
            
            # 3. ä½¿ç”¨ä»£ç†è¿›è¡Œæ–‡æœ¬åˆ†æ
            agent_analysis = self.agent.chat(f"è¯·åˆ†æè¿™ä¸ªæŸ¥è¯¢ï¼š{query_text}")
            
            result = {
                "query_text": query_text,
                "text_features": text_features.tolist(),
                "similar_antiques": similar_antiques,
                "agent_analysis": agent_analysis,
                "search_timestamp": self._get_timestamp()
            }
            
            logger.info("æ–‡æœ¬æœç´¢å¤è‘£å®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"æ–‡æœ¬æœç´¢å¤è‘£å¤±è´¥: {e}")
            raise
    
    @log_method_call("analyze_antique_text_stream")
    def analyze_antique_text_stream(self, description: str):
        """
        æµå¼åˆ†æå¤è‘£æ–‡æœ¬æè¿°ï¼Œä½¿ç”¨Qwen3æ¨¡å‹
        
        Args:
            description: å¤è‘£æ–‡æœ¬æè¿°
            
        Yields:
            åˆ†æç»“æœæ–‡æœ¬ç‰‡æ®µ
        """
        try:
            # æ„å»ºåˆ†ææç¤º
            prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“ä¸šçš„å¤è‘£é‰´å®šä¸“å®¶ï¼Œè¯·æ ¹æ®ä»¥ä¸‹è¦æ±‚è¿›è¡Œå¤è‘£åˆ†æï¼š{description}
            
è¯·æä¾›è¯¦ç»†çš„ä¸“ä¸šé‰´å®šåˆ†æï¼ŒåŒ…æ‹¬ï¼š
1. æ–‡ç‰©ç±»å‹å’Œåç§°
2. å¹´ä»£åˆ¤æ–­
3. æè´¨åˆ†æ
4. å·¥è‰ºç‰¹ç‚¹
5. çœŸä¼ªè¯„ä¼°
6. ä¿å­˜çŠ¶å†µ
7. å†å²ä»·å€¼

è¯·ç›´æ¥æä¾›åˆ†æç»“æœï¼Œä¸è¦é‡å¤ç”¨æˆ·çš„è¦æ±‚ã€‚è¯·ç¡®ä¿å›ç­”å®Œå…¨ä½¿ç”¨ä¸­æ–‡ï¼Œä¸è¦ä½¿ç”¨è‹±æ–‡ã€‚"""
            
            # ä¼˜å…ˆä½¿ç”¨LangChainä»£ç†ï¼ˆåŒ…å«Qwen3ï¼‰
            if self.agent and hasattr(self.agent, 'qwen3_client') and self.agent.qwen3_client:
                logger.info("ä½¿ç”¨Qwen3è¿›è¡Œæµå¼å¤è‘£æ–‡æœ¬åˆ†æ")
                
                messages = [{"role": "user", "content": prompt}]
                
                # æ£€æŸ¥æ˜¯å¦æ”¯æŒæµå¼è¾“å‡º
                if hasattr(self.agent.qwen3_client, 'chat_stream'):
                    for text_chunk in self.agent.qwen3_client.chat_stream(messages, max_length=512):
                        yield text_chunk
                else:
                    # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨æ™®é€šchatæ–¹æ³•ç„¶åæ¨¡æ‹Ÿæµå¼è¾“å‡º
                    response = self.agent.qwen3_client.chat(messages, max_length=512)
                    sentences = response.split('ã€‚')
                    for sentence in sentences:
                        if sentence.strip():
                            yield sentence.strip() + 'ã€‚'
            elif self.agent and hasattr(self.agent, '_chat_with_local_models'):
                logger.info("ä½¿ç”¨ä»£ç†æœ¬åœ°æ¨¡å‹è¿›è¡Œæµå¼å¤è‘£æ–‡æœ¬åˆ†æ")
                # ä½¿ç”¨ä»£ç†çš„æœ¬åœ°æ¨¡å‹æ–¹æ³•è·å–å®Œæ•´å›å¤ï¼Œç„¶åè¿›è¡Œæµå¼è¾“å‡º
                response = self.agent._chat_with_local_models(prompt)
                # æŒ‰å¥å­åˆ†å‰²è¿›è¡Œæµå¼è¾“å‡º
                sentences = response.split('ã€‚')
                for sentence in sentences:
                    if sentence.strip():
                        yield sentence.strip() + 'ã€‚'
            elif self.internvl3_5_client and hasattr(self.internvl3_5_client, 'text_chat'):
                logger.info("ä½¿ç”¨InternVL3_5è¿›è¡Œæµå¼å¤è‘£æ–‡æœ¬åˆ†æ")
                # å¤‡ç”¨æ–¹æ¡ˆï¼šä½¿ç”¨InternVL3_5
                response = self.internvl3_5_client.text_chat(prompt)
                # æŒ‰å¥å­åˆ†å‰²è¿›è¡Œæµå¼è¾“å‡º
                sentences = response.split('ã€‚')
                for sentence in sentences:
                    if sentence.strip():
                        yield sentence.strip() + 'ã€‚'
            else:
                yield "æ–‡æœ¬åˆ†ææ¨¡å‹ä¸å¯ç”¨ï¼Œæ— æ³•è¿›è¡Œæµå¼æ–‡æœ¬åˆ†æã€‚"
                
        except Exception as e:
            logger.error(f"æµå¼å¤è‘£æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
            yield f"åˆ†æè¿‡ç¨‹ä¸­å‡ºç°é”™è¯¯: {str(e)}"
    
    @log_method_call("analyze_antique_text")
    def analyze_antique_text(self, description: str) -> Dict[str, Any]:
        """
        åˆ†æå¤è‘£æ–‡æœ¬æè¿°
        
        Args:
            description: å¤è‘£æ–‡æœ¬æè¿°
            
        Returns:
            åˆ†æç»“æœ
        """
        try:
            # æ£€æŸ¥ç¼“å­˜
            cache_key = self._get_cache_key(description)
            if cache_key in self.text_analysis_cache:
                logger.info(f"ä»ç¼“å­˜ä¸­è·å–æ–‡æœ¬åˆ†æç»“æœ: {cache_key[:8]}...")
                cached_result = self.text_analysis_cache[cache_key].copy()
                cached_result["from_cache"] = True
                cached_result["analysis_timestamp"] = self._get_timestamp()
                return cached_result
            
            # 1. ç›´æ¥ä½¿ç”¨ä»£ç†è¿›è¡Œæ–‡æœ¬åˆ†æï¼ˆä¸è¿›è¡Œå‘é‡æ£€ç´¢ï¼‰
            agent_analysis = None
            if self.agent:
                try:
                    # ä½¿ç”¨ä»£ç†çš„æ–‡æœ¬åˆ†æåŠŸèƒ½
                    agent_result = self.agent.analyze_antique(
                        image=None,
                        text_description=description
                    )
                    agent_analysis = agent_result
                except Exception as e:
                    logger.warning(f"ä»£ç†æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
                    # å¦‚æœä»£ç†å¤±è´¥ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
                    agent_analysis = {
                        "analysis": f"æ— æ³•åˆ†ææ–‡æœ¬æè¿°: {description}",
                        "error": str(e)
                    }
            else:
                # å¦‚æœæ²¡æœ‰ä»£ç†ï¼Œè¿”å›åŸºæœ¬ä¿¡æ¯
                agent_analysis = {
                    "analysis": f"æ”¶åˆ°æ–‡æœ¬æè¿°: {description}ï¼Œä½†AIä»£ç†æœªåˆå§‹åŒ–",
                    "note": "éœ€è¦åˆå§‹åŒ–AIä»£ç†æ‰èƒ½è¿›è¡Œè¯¦ç»†åˆ†æ"
                }
            
            # 2. æ•´åˆç»“æœï¼ˆç§»é™¤å‘é‡æœç´¢ï¼‰
            result = {
                "text_analysis": agent_analysis,
                "user_description": description,
                "analysis_timestamp": self._get_timestamp(),
                "from_cache": False,
                "optimization": "è·³è¿‡å‘é‡æ£€ç´¢ï¼Œç›´æ¥ä½¿ç”¨å¤§æ¨¡å‹åˆ†æ",
                "model_info": {
                    "agent_info": self.agent.get_agent_info() if self.agent else None
                }
            }
            
            # ç¼“å­˜ç»“æœ
            self._manage_cache_size()
            self.text_analysis_cache[cache_key] = result.copy()
            logger.info(f"æ–‡æœ¬åˆ†æç»“æœå·²ç¼“å­˜: {cache_key[:8]}...")
            
            logger.info("å¤è‘£æ–‡æœ¬åˆ†æå®Œæˆ")
            return result
            
        except Exception as e:
            logger.error(f"å¤è‘£æ–‡æœ¬åˆ†æå¤±è´¥: {e}")
            raise
    
    @log_method_call("add_antique_to_database")
    def add_antique_to_database(self, antique_id: int, 
                               image: Union[str, Image.Image, np.ndarray],
                               text_description: str,
                               metadata: Dict[str, Any]) -> bool:
        """
        æ·»åŠ å¤è‘£åˆ°å‘é‡æ•°æ®åº“
        
        Args:
            antique_id: å¤è‘£ID
            image: å›¾åƒ
            text_description: æ–‡æœ¬æè¿°
            metadata: å…ƒæ•°æ®
            
        Returns:
            æ˜¯å¦æ·»åŠ æˆåŠŸ
        """
        try:
            # 1. ç¼–ç å›¾åƒå’Œæ–‡æœ¬
            image_features = self.clip_encoder.encode_image(image)
            text_features = self.clip_encoder.encode_text(text_description)
            
            # 2. åˆ†åˆ«æ·»åŠ å›¾åƒå‘é‡å’Œæ–‡æœ¬å‘é‡åˆ°å‘é‡æ•°æ®åº“
            # æ’å…¥å›¾åƒå‘é‡
            self.vector_db.insert_vectors(
                antique_ids=[antique_id],
                vectors=[image_features.tolist()],
                vector_types=["image"],
                metadata=[{**metadata, "description": text_description, "vector_type": "image"}]
            )
            
            # æ’å…¥æ–‡æœ¬å‘é‡
            self.vector_db.insert_vectors(
                antique_ids=[antique_id],
                vectors=[text_features.tolist()],
                vector_types=["text"],
                metadata=[{**metadata, "description": text_description, "vector_type": "text"}]
            )
            
            logger.info(f"æˆåŠŸæ·»åŠ å¤è‘£ {antique_id} åˆ°å‘é‡æ•°æ®åº“")
            return True
            
        except Exception as e:
            logger.error(f"æ·»åŠ å¤è‘£åˆ°æ•°æ®åº“å¤±è´¥: {e}")
            return False
    
    @log_method_call("batch_add_antiques")
    def batch_add_antiques(self, antiques_data: List[Dict[str, Any]]) -> Dict[str, Any]:
        """
        æ‰¹é‡æ·»åŠ å¤è‘£
        
        Args:
            antiques_data: å¤è‘£æ•°æ®åˆ—è¡¨ï¼Œæ¯ä¸ªå…ƒç´ åŒ…å« antique_id, image, text_description, metadata
            
        Returns:
            æ‰¹é‡æ·»åŠ ç»“æœ
        """
        try:
            results = {
                "success_count": 0,
                "failed_count": 0,
                "failed_items": []
            }
            
            for antique_data in antiques_data:
                try:
                    success = self.add_antique_to_database(
                        antique_id=antique_data["antique_id"],
                        image=antique_data["image"],
                        text_description=antique_data["text_description"],
                        metadata=antique_data["metadata"]
                    )
                    
                    if success:
                        results["success_count"] += 1
                    else:
                        results["failed_count"] += 1
                        results["failed_items"].append(antique_data["antique_id"])
                        
                except Exception as e:
                    results["failed_count"] += 1
                    results["failed_items"].append(antique_data["antique_id"])
                    logger.error(f"æ·»åŠ å¤è‘£ {antique_data['antique_id']} å¤±è´¥: {e}")
            
            logger.info(f"æ‰¹é‡æ·»åŠ å®Œæˆï¼šæˆåŠŸ {results['success_count']} ä¸ªï¼Œå¤±è´¥ {results['failed_count']} ä¸ª")
            return results
            
        except Exception as e:
            logger.error(f"æ‰¹é‡æ·»åŠ å¤è‘£å¤±è´¥: {e}")
            raise
    
    @log_method_call("remove_antique_from_database")
    def remove_antique_from_database(self, antique_id: int) -> bool:
        """
        ä»å‘é‡æ•°æ®åº“ä¸­åˆ é™¤å¤è‘£
        
        Args:
            antique_id: å¤è‘£ID
            
        Returns:
            æ˜¯å¦åˆ é™¤æˆåŠŸ
        """
        try:
            success = self.vector_db.delete_by_antique_id(antique_id)
            if success:
                logger.info(f"æˆåŠŸä»å‘é‡æ•°æ®åº“åˆ é™¤å¤è‘£ {antique_id}")
            else:
                logger.warning(f"ä»å‘é‡æ•°æ®åº“åˆ é™¤å¤è‘£ {antique_id} å¤±è´¥")
            
            return success
            
        except Exception as e:
            logger.error(f"åˆ é™¤å¤è‘£å¤±è´¥: {e}")
            return False
    
    @log_method_call("chat_with_internvl3_5")
    def chat_with_internvl3_5(self, image: Union[str, Image.Image, np.ndarray], 
                          message: str) -> str:
        """
        ä½¿ç”¨InternVL3_5æ¨¡å‹ä¸ç”¨æˆ·å¯¹è¯
        
        Args:
            image: å¤è‘£å›¾åƒ
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            InternVL3_5æ¨¡å‹å›å¤
        """
        try:
            if not self.internvl3_5_client:
                return "æŠ±æ­‰ï¼ŒInternVL3_5æ¨¡å‹æœªåˆå§‹åŒ–ï¼Œè¯·æ£€æŸ¥é…ç½®ã€‚"
            
            response = self.internvl3_5_client.chat_about_antique(image, message)
            return response
            
        except Exception as e:
            logger.error(f"ä¸InternVL3_5æ¨¡å‹å¯¹è¯å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯: {str(e)}"
    
    def chat_with_smolvlm2(self, image: Union[str, Image.Image, np.ndarray], 
                          message: str) -> str:
        """
        ä½¿ç”¨SmolVLM2æ¨¡å‹ä¸ç”¨æˆ·å¯¹è¯ï¼ˆå…¼å®¹æ€§æ–¹æ³•ï¼Œå®é™…ä½¿ç”¨InternVL3_5ï¼‰
        
        Args:
            image: å¤è‘£å›¾åƒ
            message: ç”¨æˆ·æ¶ˆæ¯
            
        Returns:
            InternVL3_5æ¨¡å‹å›å¤
        """
        # ä¸ºäº†ä¿æŒå‘åå…¼å®¹æ€§ï¼Œé‡å®šå‘åˆ°æ–°çš„æ–¹æ³•
        return self.chat_with_internvl3_5(image, message)
    
    @log_method_call("chat_with_agent")
    def chat_with_agent(self, message: str, image: Union[str, Image.Image, np.ndarray] = None) -> str:
        """
        ä¸ AI ä»£ç†å¯¹è¯ï¼ˆæ”¯æŒæœ¬åœ°æ¨¡å‹æ··åˆä½¿ç”¨ï¼‰
        
        Args:
            message: ç”¨æˆ·æ¶ˆæ¯
            image: å¯é€‰çš„å›¾åƒè¾“å…¥
            
        Returns:
            ä»£ç†å›å¤
        """
        try:
            if not self.agent:
                return "æŠ±æ­‰ï¼ŒAIä»£ç†æœªåˆå§‹åŒ–ã€‚"
            
            response = self.agent.chat(message, image)
            return response
            
        except Exception as e:
            logger.error(f"ä¸ä»£ç†å¯¹è¯å¤±è´¥: {e}")
            return f"æŠ±æ­‰ï¼Œå¤„ç†æ‚¨çš„æ¶ˆæ¯æ—¶å‡ºç°é”™è¯¯: {str(e)}"
    
    @log_method_call("get_system_status")
    def get_system_status(self) -> Dict[str, Any]:
        """
        è·å–ç³»ç»ŸçŠ¶æ€
        
        Returns:
            ç³»ç»ŸçŠ¶æ€ä¿¡æ¯
        """
        try:
            status = {
                "clip_encoder": self.clip_encoder.get_model_info() if self.clip_encoder else None,
                "vector_db": self.vector_db.get_collection_stats() if self.vector_db else None,
                "agent": self.agent.get_agent_info() if self.agent else None,
                "internvl3_5_client": self.internvl3_5_client.get_model_info() if self.internvl3_5_client else None,
                "system_timestamp": self._get_timestamp()
            }
            
            return status
            
        except Exception as e:
            logger.error(f"è·å–ç³»ç»ŸçŠ¶æ€å¤±è´¥: {e}")
            raise
    
    @log_method_call("get_conversation_history")
    def get_conversation_history(self) -> List[Dict[str, str]]:
        """
        è·å–å¯¹è¯å†å²
        
        Returns:
            å¯¹è¯å†å²åˆ—è¡¨
        """
        try:
            return self.agent.get_conversation_history()
            
        except Exception as e:
            logger.error(f"è·å–å¯¹è¯å†å²å¤±è´¥: {e}")
            return []
    
    @log_method_call("clear_conversation_history")
    def clear_conversation_history(self):
        """æ¸…é™¤å¯¹è¯å†å²"""
        try:
            self.agent.clear_memory()
            logger.info("å¯¹è¯å†å²å·²æ¸…é™¤")
            
        except Exception as e:
            logger.error(f"æ¸…é™¤å¯¹è¯å†å²å¤±è´¥: {e}")
    
    def _init_cache(self):
        """åˆå§‹åŒ–ç¼“å­˜ç³»ç»Ÿ"""
        import hashlib
        self.text_analysis_cache = {}  # æ–‡æœ¬åˆ†æç»“æœç¼“å­˜
        self.cache_max_size = 100  # æœ€å¤§ç¼“å­˜æ¡ç›®æ•°
        logger.info("ç¼“å­˜ç³»ç»Ÿåˆå§‹åŒ–å®Œæˆ")
    
    def _get_cache_key(self, text: str) -> str:
        """ç”Ÿæˆç¼“å­˜é”®"""
        import hashlib
        return hashlib.md5(text.encode('utf-8')).hexdigest()
    
    def _manage_cache_size(self):
        """ç®¡ç†ç¼“å­˜å¤§å°ï¼Œé˜²æ­¢å†…å­˜æº¢å‡º"""
        if len(self.text_analysis_cache) > self.cache_max_size:
            # åˆ é™¤æœ€æ—§çš„ç¼“å­˜æ¡ç›®
            oldest_key = next(iter(self.text_analysis_cache))
            del self.text_analysis_cache[oldest_key]
            logger.debug(f"åˆ é™¤æœ€æ—§çš„ç¼“å­˜æ¡ç›®: {oldest_key}")
    
    def _get_timestamp(self) -> str:
        """è·å–å½“å‰æ—¶é—´æˆ³"""
        from datetime import datetime
        return datetime.now().isoformat()
    
    @log_method_call("close")
    def close(self):
        """å…³é—­æ‰€æœ‰è¿æ¥"""
        try:
            if self.vector_db:
                self.vector_db.close()
            if self.internvl3_5_client:
                self.internvl3_5_client.cleanup()
            logger.info("AI æ ¸å¿ƒå·²å…³é—­")
            
        except Exception as e:
            logger.error(f"å…³é—­ AI æ ¸å¿ƒå¤±è´¥: {e}")
    
    def __enter__(self):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å…¥å£"""
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        """ä¸Šä¸‹æ–‡ç®¡ç†å™¨å‡ºå£"""
        self.close()
