# AI鉴宝师项目环境变量配置示例
# 复制此文件为 .env 并根据需要修改配置值

# OpenAI API密钥（可选，用于LangChain代理功能）
OPENAI_API_KEY=your_openai_api_key_here

# Milvus向量数据库配置
MILVUS_HOST=localhost
MILVUS_PORT=19530

# SmolVLM2 模型配置
# 可以设置本地模型路径，留空使用默认路径
SMOLVLM2_MODEL_PATH=

# SmolVLM2 生成参数
# 最大生成token数
MAX_TOKENS=512

# 生成温度（0.0-1.0，越高越随机）
TEMPERATURE=0.7

# 模型配置说明：
# SmolVLM2 是一个轻量级的多模态模型（2.2B参数）
# - 支持图像和文本理解
# - 适合边缘设备部署
# - GPU 显存需求约5.2GB
# - 支持 CPU 和 GPU 推理
#
# 本地模型路径示例：
#    SMOLVLM2_MODEL_PATH=./ai_core/SmolVLM2_model
#
# 使用 HuggingFace 模型（默认）：
#    SMOLVLM2_MODEL_PATH=HuggingFaceTB/SmolVLM2-2.2B-Base

# ===== 应用配置 =====
# Flask 应用密钥
SECRET_KEY=your-secret-key-here

# 日志级别
LOG_LEVEL=INFO

# 搜索配置
DEFAULT_TOP_K=10
DEFAULT_SCORE_THRESHOLD=0.5

# 缓存配置
ENABLE_CACHE=true
CACHE_TTL=3600

# 性能配置
BATCH_SIZE=32
MAX_CONCURRENT_REQUESTS=10

# ===== 部署配置 =====
# 应用端口
FLASK_PORT=5000

# 是否启用调试模式
FLASK_DEBUG=false

# 上传文件大小限制（字节）
MAX_CONTENT_LENGTH=16777216

# 允许的文件类型
ALLOWED_EXTENSIONS=jpg,jpeg,png,gif,bmp,webp